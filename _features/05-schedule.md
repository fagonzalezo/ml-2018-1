---
id: schedule
name: Schedule
heading: Course schedule
subheading: 
image: 
---

<table class="table table-condensed">
	<tbody>
		<tr>
			<th>Week</th>
			<th>Topic</th>
			<th>Material</th>
			<th>Assignments</th>
		</tr>
			<tr>
				<td>Feb 7</td>
				<td>1. Introduction</td>
				<td>
					Brief Introduction to ML (<a href= "introduction_ml.pdf">slides</a>)<br>
					<a href= "http://videolectures.net/bootcamp07_keller_bss/">Linear Algebra and Probability Review</a> (part 1 Linear Algebra, part 2 Probability)
				</td>
				<td>
				<a href= "assign1.pdf">Assignment 1</a>
				</td>
			</tr>
			<tr>
				<td>Feb 14</td>
				<td>2.1 Bayesian decision theory</td>
				<td>
					[Alp10] Chap 3 (<a href= "http://www.cmpe.boun.edu.tr/~ethem/i2ml2e/2e_v1-0/i2ml2e-chap3-v1-0.pdf">slides</a>)<br>
				</td>
				<td>
				</td>
			</tr>
			<tr>
				<td>Feb 21</td>
				<td>2.2 Estimation</td>
				<td>
					[Alp10] Chap 4 (<a href= "http://www.cmpe.boun.edu.tr/~ethem/i2ml2e/2e_v1-0/i2ml2e-chap4-v1-0.pdf">slides</a>)<br>
					Bias and variance (<a href= "http://nbviewer.ipython.org/6788818">IPython notebook</a>)<br>
				</td>
				<td>
				<a href= "assign2.pdf">Assignment 2</a>
				</td>
			</tr>
			<tr>
				<td>Feb 28</td>
				<td>2.3 Linear models</td>
				<td>
					[Alp10] Chap 10 (<a href= "http://www.cmpe.boun.edu.tr/~ethem/i2ml2e/2e_v1-0/i2ml2e-chap10-v1-0.pdf">slides</a>)<br>
				</td>
				<td>
				</td>
			</tr>
			<tr>
				<td>Mar 7</td>
				<td>3.2 Kernel methods</td>
				<td>
					Introduction to kernel methods (<a href= "https://fagonzalezo.github.io/ml-2016-2/kernels.pdf">slides</a>)<br>
					[Alp10] Chap 13 (<a href= "http://www.cmpe.boun.edu.tr/~ethem/i2ml2e/2e_v1-0/i2ml2e-chap13-v1-0.pdf">slides</a>)<br>
				</td>
				<td>
				</td>
			</tr>
			<tr>
				<td>Mar 14</td>
				<td>4.1 Support vector learning</td>
				<td>
					[Alp10] Chap 13 (<a href= "http://www.cmpe.boun.edu.tr/~ethem/i2ml2e/2e_v1-0/i2ml2e-chap13-v1-0.pdf">slides</a>)<br>
					<a href="http://axiom.anu.edu.au/%7Edaa/courses/GSAC6017/tekbac_4.pdf">An
						introduction to ML</a>, Smola<br>
					<a href="http://www1.cs.columbia.edu/%7Ekathy/cs4701/documents/jason_svm_tutorial.pdf">Support
						Vector Machine Tutorial</a>, Weston<br>
				</td>
				<td>
				<a href= "assign3.pdf">Assignment 3</a>
				</td>
			</tr>
			<tr>
				<td>Mar 21</td>
				<td>4.3. Neural network learning </td>
				<td>
					[Alp10] Chap 11 (<a href= "http://www.cmpe.boun.edu.tr/~ethem/i2ml2e/2e_v1-0/i2ml2e-chap11-v1-0.pdf">slides</a>)<br>
					Quick and dirty introduction to neural networks (<a href= "https://gist.github.com/fagonzalezo/c1f56629890dcf5670aa">IPython notebook</a>)<br>
				</td>
				<td>
				</td>
			</tr>
			<tr>
				<td>
				</td>
				<td>3.3 Representation learning </td>
				<td>
					Deep Learning, Andrew Ng (<a href= "http://research.microsoft.com/en-us/events/fs2013/andrew-ng_machinelearning.pdf">slides</a>)<br>
					Deep Learning Tutorial, Yann LeCun (<a href= "http://www.cs.nyu.edu/~yann/talks/lecun-ranzato-icml2013.pdf">slides</a>)<br>
					How we're teaching computers to understand pictures, Li Fei-Fei (<a href= "https://www.ted.com/talks/fei_fei_li_how_we_re_teaching_computers_to_understand_pictures?language=en">slides</a>)<br>
					<a href= "https://fagonzalezo.github.io/dl_tutorial_upv/">Representation Learning and Deep Learning Tutorial</a> <br>
				</td>
				<td>
				</td>
			</tr>
			<tr>
				<td></td>
				<td>4.2 Random forest learning</td>
				<td>
					[HTF09] Chap 15 (<a href= "http://statweb.stanford.edu/~tibs/ElemStatLearn/">book</a>)<br>
					Random Forest and Boosting, Trevor Hastie (<a href= "http://www.slideshare.net/0xdata/gbm-27891077">slides</a>)<br>
					Trees and Random Forest, Markus Kalisch (<a href= "https://stat.ethz.ch/education/semesters/ss2012/ams/slides/v10.1.pdf">slides1</a>, <a href= "https://stat.ethz.ch/education/semesters/ss2012/ams/slides/v10.2.pdf">slides2</a>)<br>
				</td>
				<td>
				</td>
			</tr>
			<tr>
				<td></td>
				<td>5.1 Mixture densities </td>
				<td>
					[Alp10] Chap 7 (<a href= "http://www.cmpe.boun.edu.tr/~ethem/i2ml2e/2e_v1-0/i2ml2e-chap7-v1-0.pdf">slides</a>)<br>
				</td>
				<td>
				</td>
			</tr>
			<tr>
				<td></td>
				<td>5.2 Latent topic models<br>5.3 Matrix factorization </td>
				<td>
					Latent Semantic Analysis, CS158 Pomona College (<a href= "http://www.cs.pomona.edu/classes/cs158/resources/158-12(LSA).pdf">slides</a>)<br>
					Latent Semantic Variable Models, Thomas Hofmann (<a href= "http://videolectures.net/slsfs05_hofmann_lsvm/">videolecture</a>)<br>
				</td>
				<td>
				</td>
			</tr>
			<tr>
				<td></td>
				<td>5.3 Matrix factorization<br>6.2 Large scale machine learning </td>
				<td>
					Two-way Multimodal Online Matrix Factorization, Jorge Vanegas (<a href= "Two-wayMatrixFactorization.pdf">slides</a>)<br>
					Online Kernel Matrix Factorizatioon, Esteban Paez (<a href= "http://slides.com/aepaezt/deck#/">slides</a>)<br>
				</td>
				<td>
				</td>
			</tr>
			<tr>
				<td></td>
				<td>6.1 Experimental design</td>
				<td>
					[Alp10] Chap 19 (<a href= "http://www.cmpe.boun.edu.tr/~ethem/i2ml2e/2e_v1-0/i2ml2e-chap19-v1-0.pdf">slides</a>)<br>
				</td>
				<td>
				</td>
			</tr>
			</tbody>
		</table>
